{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812b5b36-711f-4713-83b3-17489773a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Operating system interfaces\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras    # TensorFlow deep learning framework\n",
    "from tensorflow.keras import layers, regularizers\n",
    "# import matplotlib.pyplot as plt                            # Plotting library\n",
    "# import matplotlib.image as mpimg                           # Image loading and manipulation library\n",
    "from tensorflow.keras.models import Sequential, Model      # Sequential and Functional API for building models\n",
    "from tensorflow.keras.optimizers import Adam               # Adam optimizer for model training\n",
    "from tensorflow.keras.callbacks import EarlyStopping       # Early stopping callback for model training\n",
    "from tensorflow.keras.regularizers import l1, l2           # L1 and L2 regularization for model regularization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Data augmentation and preprocessing for images\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, BatchNormalization\n",
    "# Various types of layers for building neural networks\n",
    "from tensorflow.keras.applications import DenseNet121, EfficientNetB4, Xception, VGG16, VGG19 # Pre-trained models for transfer learning\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f613f20-23ce-487c-95b8-98e76dd74c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22000 files belonging to 10 classes.\n",
      "Found 4500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "directory = './Desktop/Disease/train_black_aug_new'\n",
    "\n",
    "# Load the dataset\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory=directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)  # Ensure this matches your model's input size\n",
    ")\n",
    "\n",
    "\n",
    "# Define the path to the dataset\n",
    "directory_val = './Desktop/Disease/val_black_aug_new'\n",
    "\n",
    "# Load the dataset\n",
    "val_ds = image_dataset_from_directory(\n",
    "    directory=directory_val,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224)  # Ensure this matches your model's input size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7399e99b-2551-4aa9-9578-5b8fc552a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 102s 2us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv_base_VGG16 = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling='avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376332d4-3c49-4bfd-b317-89b7227be8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_VGG16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e421ef19-6004-48e8-b140-60824e25fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an Input layer to define the input shape for the model\n",
    "from tensorflow.keras.layers import Input  # Import the Input class\n",
    "\n",
    "model_VGG = Sequential()\n",
    "# model_VGG.add(Input(shape=(224, 224, 3)))  # Define the input shape here\n",
    "model_VGG.add(conv_base_VGG16)\n",
    "model_VGG.add(Flatten())\n",
    "\n",
    "model_VGG.add(BatchNormalization())\n",
    "model_VGG.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_VGG.add(Dropout(0.35))\n",
    "\n",
    "model_VGG.add(BatchNormalization())\n",
    "model_VGG.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_VGG.add(Dropout(0.35))\n",
    "\n",
    "model_VGG.add(BatchNormalization())\n",
    "model_VGG.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_VGG.add(Dropout(0.35))\n",
    "\n",
    "model_VGG.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37e3503-5991-4f7d-a114-f768f8c4aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,147,978\n",
      "Trainable params: 430,730\n",
      "Non-trainable params: 14,717,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_VGG.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "model_VGG.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "860a520e-b4dd-4056-8c75-ed6c4492bea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "688/688 [==============================] - 297s 408ms/step - loss: 8.2338 - accuracy: 0.4847 - val_loss: 2.1813 - val_accuracy: 0.7211\n",
      "Epoch 2/70\n",
      "688/688 [==============================] - 266s 386ms/step - loss: 1.9133 - accuracy: 0.7277 - val_loss: 1.6149 - val_accuracy: 0.7242\n",
      "Epoch 3/70\n",
      "688/688 [==============================] - 268s 389ms/step - loss: 1.6301 - accuracy: 0.7264 - val_loss: 1.5850 - val_accuracy: 0.7491\n",
      "Epoch 4/70\n",
      "688/688 [==============================] - 279s 404ms/step - loss: 1.6338 - accuracy: 0.7334 - val_loss: 1.6173 - val_accuracy: 0.7409\n",
      "Epoch 5/70\n",
      "688/688 [==============================] - 282s 409ms/step - loss: 1.6410 - accuracy: 0.7398 - val_loss: 1.6376 - val_accuracy: 0.7449\n",
      "Epoch 6/70\n",
      "688/688 [==============================] - 285s 414ms/step - loss: 1.6490 - accuracy: 0.7339 - val_loss: 1.6432 - val_accuracy: 0.7467\n",
      "Epoch 7/70\n",
      "688/688 [==============================] - 288s 418ms/step - loss: 1.6456 - accuracy: 0.7425 - val_loss: 1.6143 - val_accuracy: 0.7593\n",
      "Epoch 8/70\n",
      "688/688 [==============================] - 292s 424ms/step - loss: 1.6519 - accuracy: 0.7401 - val_loss: 1.6738 - val_accuracy: 0.7504\n",
      "Epoch 9/70\n",
      "688/688 [==============================] - 295s 428ms/step - loss: 1.6535 - accuracy: 0.7396 - val_loss: 1.6248 - val_accuracy: 0.7542\n",
      "Epoch 10/70\n",
      "688/688 [==============================] - 299s 434ms/step - loss: 1.6400 - accuracy: 0.7459 - val_loss: 1.6123 - val_accuracy: 0.7542\n",
      "Epoch 11/70\n",
      "688/688 [==============================] - 302s 438ms/step - loss: 1.6240 - accuracy: 0.7432 - val_loss: 1.5795 - val_accuracy: 0.7658\n",
      "Epoch 12/70\n",
      "688/688 [==============================] - 305s 442ms/step - loss: 1.6509 - accuracy: 0.7361 - val_loss: 1.6092 - val_accuracy: 0.7602\n",
      "Epoch 13/70\n",
      "688/688 [==============================] - 325s 472ms/step - loss: 1.6269 - accuracy: 0.7517 - val_loss: 1.5927 - val_accuracy: 0.7593\n",
      "Epoch 14/70\n",
      "688/688 [==============================] - 310s 450ms/step - loss: 1.6080 - accuracy: 0.7499 - val_loss: 1.6147 - val_accuracy: 0.7540\n",
      "Epoch 15/70\n",
      "688/688 [==============================] - 311s 452ms/step - loss: 1.6127 - accuracy: 0.7481 - val_loss: 1.5598 - val_accuracy: 0.7609\n",
      "Epoch 16/70\n",
      "688/688 [==============================] - 300s 435ms/step - loss: 1.5956 - accuracy: 0.7450 - val_loss: 1.6184 - val_accuracy: 0.7380\n",
      "Epoch 17/70\n",
      "688/688 [==============================] - 298s 432ms/step - loss: 1.6013 - accuracy: 0.7414 - val_loss: 1.5541 - val_accuracy: 0.7582\n",
      "Epoch 18/70\n",
      "688/688 [==============================] - 293s 425ms/step - loss: 1.5892 - accuracy: 0.7467 - val_loss: 1.5352 - val_accuracy: 0.7589\n",
      "Epoch 19/70\n",
      "688/688 [==============================] - 297s 431ms/step - loss: 1.5655 - accuracy: 0.7520 - val_loss: 1.5097 - val_accuracy: 0.7676\n",
      "Epoch 20/70\n",
      "688/688 [==============================] - 299s 433ms/step - loss: 1.5634 - accuracy: 0.7455 - val_loss: 1.5236 - val_accuracy: 0.7600\n",
      "Epoch 21/70\n",
      "688/688 [==============================] - 301s 436ms/step - loss: 1.5678 - accuracy: 0.7473 - val_loss: 1.4913 - val_accuracy: 0.7667\n",
      "Epoch 22/70\n",
      "688/688 [==============================] - 303s 439ms/step - loss: 1.5643 - accuracy: 0.7449 - val_loss: 1.4964 - val_accuracy: 0.7591\n",
      "Epoch 23/70\n",
      "688/688 [==============================] - 312s 453ms/step - loss: 1.5083 - accuracy: 0.7559 - val_loss: 1.5002 - val_accuracy: 0.7582\n",
      "Epoch 24/70\n",
      "688/688 [==============================] - 309s 448ms/step - loss: 1.5222 - accuracy: 0.7516 - val_loss: 1.4980 - val_accuracy: 0.7562\n",
      "Epoch 25/70\n",
      "688/688 [==============================] - 311s 451ms/step - loss: 1.5265 - accuracy: 0.7472 - val_loss: 1.5059 - val_accuracy: 0.7553\n",
      "Epoch 26/70\n",
      "688/688 [==============================] - 317s 460ms/step - loss: 1.5051 - accuracy: 0.7487 - val_loss: 1.4735 - val_accuracy: 0.7618\n",
      "Epoch 27/70\n",
      "688/688 [==============================] - 321s 466ms/step - loss: 1.5077 - accuracy: 0.7521 - val_loss: 1.4438 - val_accuracy: 0.7716\n",
      "Epoch 28/70\n",
      "688/688 [==============================] - 325s 472ms/step - loss: 1.4997 - accuracy: 0.7514 - val_loss: 1.4505 - val_accuracy: 0.7571\n",
      "Epoch 29/70\n",
      "688/688 [==============================] - 321s 466ms/step - loss: 1.4945 - accuracy: 0.7452 - val_loss: 1.4216 - val_accuracy: 0.7753\n",
      "Epoch 30/70\n",
      "688/688 [==============================] - 326s 473ms/step - loss: 1.4843 - accuracy: 0.7446 - val_loss: 1.4523 - val_accuracy: 0.7604\n",
      "Epoch 31/70\n",
      "688/688 [==============================] - 325s 471ms/step - loss: 1.4773 - accuracy: 0.7459 - val_loss: 1.4404 - val_accuracy: 0.7604\n",
      "Epoch 32/70\n",
      "688/688 [==============================] - 330s 478ms/step - loss: 1.4687 - accuracy: 0.7544 - val_loss: 1.4137 - val_accuracy: 0.7718\n",
      "Epoch 33/70\n",
      "688/688 [==============================] - 329s 477ms/step - loss: 1.4654 - accuracy: 0.7502 - val_loss: 1.3977 - val_accuracy: 0.7689\n",
      "Epoch 34/70\n",
      "688/688 [==============================] - 338s 490ms/step - loss: 1.4472 - accuracy: 0.7499 - val_loss: 1.4661 - val_accuracy: 0.7518\n",
      "Epoch 35/70\n",
      "688/688 [==============================] - 336s 487ms/step - loss: 1.4562 - accuracy: 0.7453 - val_loss: 1.4359 - val_accuracy: 0.7558\n",
      "Epoch 36/70\n",
      "688/688 [==============================] - 342s 496ms/step - loss: 1.4579 - accuracy: 0.7399 - val_loss: 1.4187 - val_accuracy: 0.7562\n",
      "Epoch 37/70\n",
      "688/688 [==============================] - 346s 502ms/step - loss: 1.4342 - accuracy: 0.7543 - val_loss: 1.3863 - val_accuracy: 0.7716\n",
      "Epoch 38/70\n",
      "688/688 [==============================] - 357s 518ms/step - loss: 1.4318 - accuracy: 0.7484 - val_loss: 1.3887 - val_accuracy: 0.7662\n",
      "Epoch 39/70\n",
      "688/688 [==============================] - 364s 528ms/step - loss: 1.4246 - accuracy: 0.7492 - val_loss: 1.3605 - val_accuracy: 0.7733\n",
      "Epoch 40/70\n",
      "688/688 [==============================] - 368s 534ms/step - loss: 1.4273 - accuracy: 0.7500 - val_loss: 1.3700 - val_accuracy: 0.7631\n",
      "Epoch 41/70\n",
      "688/688 [==============================] - 378s 548ms/step - loss: 1.4233 - accuracy: 0.7535 - val_loss: 1.3475 - val_accuracy: 0.7656\n",
      "Epoch 42/70\n",
      "688/688 [==============================] - 390s 565ms/step - loss: 1.3979 - accuracy: 0.7493 - val_loss: 1.3630 - val_accuracy: 0.7682\n",
      "Epoch 43/70\n",
      "688/688 [==============================] - 373s 541ms/step - loss: 1.4003 - accuracy: 0.7521 - val_loss: 1.3659 - val_accuracy: 0.7553\n",
      "Epoch 44/70\n",
      "688/688 [==============================] - 376s 545ms/step - loss: 1.4067 - accuracy: 0.7557 - val_loss: 1.3527 - val_accuracy: 0.7660\n",
      "Epoch 45/70\n",
      "688/688 [==============================] - 377s 547ms/step - loss: 1.3610 - accuracy: 0.7623 - val_loss: 1.3403 - val_accuracy: 0.7740\n",
      "Epoch 46/70\n",
      "688/688 [==============================] - 381s 553ms/step - loss: 1.3897 - accuracy: 0.7468 - val_loss: 1.3442 - val_accuracy: 0.7787\n",
      "Epoch 47/70\n",
      "688/688 [==============================] - 384s 556ms/step - loss: 1.3822 - accuracy: 0.7510 - val_loss: 1.3161 - val_accuracy: 0.7833\n",
      "Epoch 48/70\n",
      "688/688 [==============================] - 408s 591ms/step - loss: 1.3930 - accuracy: 0.7492 - val_loss: 1.3377 - val_accuracy: 0.7740\n",
      "Epoch 49/70\n",
      "688/688 [==============================] - 405s 586ms/step - loss: 1.3941 - accuracy: 0.7517 - val_loss: 1.3223 - val_accuracy: 0.7729\n",
      "Epoch 50/70\n",
      "688/688 [==============================] - 394s 572ms/step - loss: 1.4029 - accuracy: 0.7475 - val_loss: 1.3675 - val_accuracy: 0.7598\n",
      "Epoch 51/70\n",
      "688/688 [==============================] - 417s 605ms/step - loss: 1.3800 - accuracy: 0.7490 - val_loss: 1.3515 - val_accuracy: 0.7669\n",
      "Epoch 52/70\n",
      "688/688 [==============================] - 401s 581ms/step - loss: 1.3831 - accuracy: 0.7485 - val_loss: 1.3044 - val_accuracy: 0.7720\n",
      "Epoch 53/70\n",
      "688/688 [==============================] - 426s 616ms/step - loss: 1.3494 - accuracy: 0.7574 - val_loss: 1.3096 - val_accuracy: 0.7718\n",
      "Epoch 54/70\n",
      "688/688 [==============================] - 413s 599ms/step - loss: 1.3606 - accuracy: 0.7587 - val_loss: 1.3360 - val_accuracy: 0.7638\n",
      "Epoch 55/70\n",
      "688/688 [==============================] - 464s 671ms/step - loss: 1.3553 - accuracy: 0.7587 - val_loss: 1.3320 - val_accuracy: 0.7644\n",
      "Epoch 56/70\n",
      "688/688 [==============================] - 431s 623ms/step - loss: 1.3795 - accuracy: 0.7470 - val_loss: 1.2982 - val_accuracy: 0.7740\n",
      "Epoch 57/70\n",
      "688/688 [==============================] - 413s 598ms/step - loss: 1.3462 - accuracy: 0.7549 - val_loss: 1.3221 - val_accuracy: 0.7587\n",
      "Epoch 58/70\n",
      "688/688 [==============================] - 414s 599ms/step - loss: 1.3373 - accuracy: 0.7517 - val_loss: 1.2627 - val_accuracy: 0.7756\n",
      "Epoch 59/70\n",
      "688/688 [==============================] - 423s 613ms/step - loss: 1.3563 - accuracy: 0.7501 - val_loss: 1.2781 - val_accuracy: 0.7716\n",
      "Epoch 60/70\n",
      "688/688 [==============================] - 427s 619ms/step - loss: 1.3399 - accuracy: 0.7540 - val_loss: 1.2723 - val_accuracy: 0.7756\n",
      "Epoch 61/70\n",
      "688/688 [==============================] - 423s 612ms/step - loss: 1.3303 - accuracy: 0.7503 - val_loss: 1.2792 - val_accuracy: 0.7749\n",
      "Epoch 62/70\n",
      "688/688 [==============================] - 437s 632ms/step - loss: 1.3395 - accuracy: 0.7523 - val_loss: 1.2972 - val_accuracy: 0.7687\n",
      "Epoch 63/70\n",
      "688/688 [==============================] - 439s 635ms/step - loss: 1.3493 - accuracy: 0.7519 - val_loss: 1.2896 - val_accuracy: 0.7767\n",
      "Epoch 64/70\n",
      "688/688 [==============================] - 443s 642ms/step - loss: 1.3346 - accuracy: 0.7571 - val_loss: 1.3215 - val_accuracy: 0.7616\n",
      "Epoch 65/70\n",
      "688/688 [==============================] - 461s 667ms/step - loss: 1.3520 - accuracy: 0.7474 - val_loss: 1.2821 - val_accuracy: 0.7689\n",
      "Epoch 66/70\n",
      "688/688 [==============================] - 453s 655ms/step - loss: 1.3413 - accuracy: 0.7520 - val_loss: 1.2735 - val_accuracy: 0.7782\n",
      "Epoch 67/70\n",
      "688/688 [==============================] - 448s 649ms/step - loss: 1.3312 - accuracy: 0.7529 - val_loss: 1.2892 - val_accuracy: 0.7644\n",
      "Epoch 68/70\n",
      "688/688 [==============================] - 453s 655ms/step - loss: 1.3289 - accuracy: 0.7520 - val_loss: 1.2926 - val_accuracy: 0.7629\n",
      "Epoch 69/70\n",
      "688/688 [==============================] - 443s 642ms/step - loss: 1.3146 - accuracy: 0.7523 - val_loss: 1.2537 - val_accuracy: 0.7751\n",
      "Epoch 70/70\n",
      "688/688 [==============================] - 448s 648ms/step - loss: 1.3078 - accuracy: 0.7531 - val_loss: 1.2840 - val_accuracy: 0.7733\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(train_ds,epochs=10,validation_data=validation_ds)\n",
    "history = model_VGG.fit(train_ds, epochs=70, validation_data=val_ds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063c3c1d-9055-4e18-8af2-d883bb206a9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m acc_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest epoch= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(index_acc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfivethirtyeight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Define needed variables\n",
    "import numpy as np\n",
    "tr_acc = history.history['accuracy']\n",
    "tr_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "index_acc = np.argmax(val_acc)\n",
    "acc_highest = val_acc[index_acc]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Epochs, tr_loss, 'pink', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'green', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Epochs, tr_acc, 'pink', label= 'Training Accuracy')\n",
    "plt.plot(Epochs, val_acc, 'green', label= 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74369b02-2d8b-49ee-bdac-46892581203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation data\n",
    "evaluation_VGG = model_VGG.evaluate(val_ds_VGG)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Validation Loss:\", evaluation_VGG[0])\n",
    "print(\"Validation Accuracy:\", evaluation_VGG[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
